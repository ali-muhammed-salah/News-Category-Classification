# ðŸ“° News Category Classification â€“ NLP Task

### ðŸš€ **ELEVVO Internship Project**

* ðŸ‘¤ **Author:** Ali Muhammed  
* ðŸ§  **Task Level:** 1  
* ðŸš€ **Task Number:** 2  

---

## ðŸŽ¯ **Objective**

Develop a machine learning and neural network model to classify **news articles** into **multiple categories** using NLP and deep learning techniques.

---

## ðŸ“ **Dataset**

* **Files:** `train.csv`, `test.csv`
* **Columns Used:**
  * `TITLE` (News headline)
  * `DESCRIPTION` (News summary)
  * `CATEGORY` (Target class)

* **Classes:** Multiple news topics (Politics, Sports, business, Science Technology)

---

## ðŸ›  **Tools & Libraries**

* ðŸ Python  
* ðŸ“Š Pandas  
* ðŸ”¡ re (Regular Expressions)  
* âœ‚ï¸ NLTK  
* ðŸ”¢ Collections  
* ðŸ“ˆ Matplotlib  
* â˜ï¸ WordCloud  
* ðŸ¤– Scikit-learn  
* ðŸ”¥ XGBoost  
* ðŸ§  TensorFlow / Keras  

---

## ðŸ”„ **Workflow Overview**

### ðŸ§¹ **1. Data Cleaning & Preprocessing**
* ðŸ”¡ Converted text to lowercase  
* ðŸš« Removed punctuation, symbols, and stopwords  
* âœ‚ï¸ Tokenized and joined cleaned words for training  

---

### âœ¨ **2. Feature Extraction**
* Used **TF-IDF Vectorizer** for classical models
* Used **Label Encoder** and **One Hot Encoder** for neural networks  
---

### ðŸ§  **3. Model Building**

#### Classical Approach:
* **Logistic Regression Classifier**
* **Random Forest Classifier**
* **Naive Bayes Classifier**
* **XGBoost Classifier**

#### Neural Network Approach:
* Feedforward **Keras Sequential Model**  
* Input: Padded Sequences  
* Output: Multi-class Softmax  

---

### ðŸ“Š **4. Model Evaluation**

* Used metrics like **Accuracy**, **Confusion Matrix**, and **Classification Report**  
* Tracked **training/validation loss** and accuracy curves  

---

### ðŸŽ¨ **Visualizations**

#### âœ… WordCloud:
* Generated WordCloud showing the **most frequent words** in news articles.

---

## ðŸ“Š **Model Insights**

| **ðŸ’¡ Model**         | **ðŸ§© Type**          | **ðŸŽ¯ Accuracy** |
| ----------------- | ----------------- | ------------ |
| ðŸ“ˆ Logistic Regression        | Classical ML      | ~89% âœ…         |
| ðŸŒ² Random Forest        | Classical ML      | ~87% âœ…         |
| ðŸ”¬  Naive Bayes        | Classical ML      | ~89% âœ…         |
| ðŸš€ XGBoost        | Classical ML      | ~86% âœ…         |
| ðŸ¤– Neural Network | Deep Learning     | ~86% âœ…         |

---

## ðŸ’¡ **Key Learnings**

* Multi-class classification using both classical and deep learning methods  
* Text preprocessing and feature engineering  
* Evaluating and visualizing NLP models  

---

> **Note:** This task introduced **deep learning** via Keras while reinforcing core NLP skills learned.

